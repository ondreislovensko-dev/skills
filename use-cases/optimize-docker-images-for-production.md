---
title: "Optimize Docker Image Sizes for Production with AI"
slug: optimize-docker-images-for-production
description: "Reduce Docker image sizes by 60-90% through multi-stage builds, layer optimization, and base image selection guided by AI analysis."
skills: [docker-optimizer, docker-helper]
category: devops
tags: [docker, containers, optimization, multi-stage-builds, production]
---

# Optimize Docker Image Sizes for Production with AI

## The Problem

Your Docker images have quietly ballooned to 1.5 GB each. Deployments take 8 minutes because Kubernetes nodes pull massive images on every scale-up event. Your CI pipeline spends more time pushing images than running tests. The registry storage bill is climbing. You know multi-stage builds exist, but your Dockerfiles evolved organically — dev dependencies in production images, entire build toolchains baked in, node_modules with native bindings you don't need, and a base image chosen two years ago because someone copied it from a Stack Overflow answer.

## The Solution

Use the **docker-optimizer** skill to analyze and rebuild your Dockerfiles with minimal production images, and the **docker-helper** skill for general Docker configuration and troubleshooting. Install both:

```bash
npx terminal-skills install docker-optimizer docker-helper
```

## Step-by-Step Walkthrough

### 1. Audit your current images

```
Analyze all Dockerfiles in this repository. For each one, report: current base image and tag, estimated image size, number of layers, identified issues (dev dependencies in production, missing .dockerignore, unnecessary files copied, inefficient layer ordering). Show me the total registry footprint.
```

The agent examines your Dockerfiles and produces a report:

```
Image Audit Report:
┌──────────────────┬─────────────────┬──────────┬────────┬──────────────────────────┐
│ Service          │ Base Image      │ Est Size │ Layers │ Issues                   │
├──────────────────┼─────────────────┼──────────┼────────┼──────────────────────────┤
│ api              │ node:18         │ 1.4 GB   │ 23     │ Dev deps, no .dockerignore│
│ worker           │ python:3.11     │ 1.1 GB   │ 18     │ Build tools in final image│
│ frontend         │ node:18         │ 980 MB   │ 15     │ Source code in prod image │
│ migrations       │ node:18         │ 1.4 GB   │ 12     │ Full node image for CLI   │
└──────────────────┴─────────────────┴──────────┴────────┴──────────────────────────┘
Total registry footprint: ~4.9 GB per tag
```

### 2. Rewrite Dockerfiles with multi-stage builds

```
Rewrite the api Dockerfile using a multi-stage build. Stage 1: install all dependencies and compile TypeScript. Stage 2: production-only node_modules with npm ci --omit=dev. Stage 3: copy compiled JS and prod node_modules into a node:18-alpine base. Pin the Alpine version. Add proper HEALTHCHECK, non-root USER, and labels.
```

The agent rewrites the Dockerfile, reducing the API image from 1.4 GB to 180 MB.

### 3. Optimize the .dockerignore and layer caching

```
Create or update .dockerignore files for all services. Then reorder the COPY instructions in each Dockerfile to maximize layer caching — dependencies file first, install, then source code. Show me the expected cache hit scenarios for common changes (code change, dependency change, config change).
```

The agent creates `.dockerignore` files excluding `.git`, `node_modules`, test files, and documentation. It reorders layers so that a source code change only rebuilds the final 2 layers instead of 8.

### 4. Choose minimal base images

```
For each service, recommend the smallest viable base image. Compare node:18-alpine vs node:18-slim vs distroless for the Node services, and python:3.11-slim vs python:3.11-alpine vs distroless/python3 for the worker. Consider native dependency compatibility (bcrypt, sharp, psycopg2) and debugging needs. Show size comparisons.
```

```
Base Image Comparison:
- node:18          → 992 MB (full Debian, includes build tools)
- node:18-slim     → 243 MB (minimal Debian, no build tools)
- node:18-alpine   → 175 MB (musl libc — test native modules)
- distroless/nodejs18 → 128 MB (no shell, no package manager)

Recommendation: node:18-alpine for api/worker (needs shell for healthcheck),
distroless for frontend (static nginx serving, no shell needed)
```

### 5. Validate and measure results

```
Build all optimized images and compare sizes against the originals. Run the test suite against the optimized images to verify nothing is broken. Check that native modules (bcrypt, sharp) work correctly on Alpine. Generate a summary with before/after sizes and percentage reduction.
```

```
Optimization Results:
┌──────────────────┬────────────┬───────────┬───────────┐
│ Service          │ Before     │ After     │ Reduction │
├──────────────────┼────────────┼───────────┼───────────┤
│ api              │ 1.4 GB     │ 180 MB    │ -87%      │
│ worker           │ 1.1 GB     │ 145 MB    │ -87%      │
│ frontend         │ 980 MB     │ 42 MB     │ -96%      │
│ migrations       │ 1.4 GB     │ 95 MB     │ -93%      │
└──────────────────┴────────────┴───────────┴───────────┘
Total: 4.9 GB → 462 MB (-91%)
```

## Real-World Example

A platform engineer at a growing e-commerce company notices Kubernetes autoscaling is too slow — new pods take 90 seconds to become ready, with 60 seconds spent pulling the 1.4 GB API image. During a flash sale, this means dropped requests while nodes scale up.

1. They ask the agent to audit their 4 Dockerfiles and get a detailed breakdown of wasted space
2. Multi-stage builds separate the TypeScript compiler and dev dependencies from the production runtime
3. Switching from `node:18` to `node:18-alpine` and using distroless for the static frontend cuts image sizes by 91%
4. Layer reordering means most deployments only push 2-3 changed layers (~15 MB) instead of the full image
5. Pod startup drops from 90 seconds to 18 seconds, and the monthly registry storage bill goes from $45 to $6

The next flash sale, autoscaling handles a 4x traffic spike with zero dropped requests.

## Related Skills

- [docker-helper](../skills/docker-helper/) — General Docker configuration and troubleshooting
- [cicd-pipeline](../skills/cicd-pipeline/) — Integrates optimized builds into CI/CD workflows
